{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b57eb45",
   "metadata": {},
   "source": [
    "# Demo 2: Automated Loss Landscape Analysis Workflow\n",
    "\n",
    "This notebook demonstrates how to use the **automated command-line scripts** for Hessian eigenvector computation and loss landscape generation, providing a streamlined alternative to the manual step-by-step approach shown in Demo 1.\n",
    "\n",
    "## **What This Demo Covers**\n",
    "1. **Use configuration files** to specify parameters\n",
    "2. **Execute automated scripts** via command line\n",
    "\n",
    "## **Expected Generated Files**\n",
    "\n",
    "This automated workflow will create the following files and directories:\n",
    "\n",
    "### **Configuration Files (Demo Directory):**\n",
    "- `demo2_hessian_config.yml` - Configuration for Hessian eigenvector computation\n",
    "- `demo2_landscape_config.yml` - Configuration for loss landscape generation\n",
    "\n",
    "#### The result files should be identical to the ones generated in demo1\n",
    "\n",
    "### **Hessian Eigenvector Results (`eigenvectors/demo2_automated_hessian/`):**\n",
    "- `model_eig_max.pt` - Model with weights set to maximum eigenvector\n",
    "- `model_eig_min.pt` - Model with weights set to minimum eigenvector\n",
    "- `config.yml` - Copy of the Hessian computation configuration\n",
    "- `eigenvalues.txt` - Text file with computed eigenvalue statistics\n",
    "\n",
    "### **Loss Landscape Results (`computed_loss_landscapes/demo2_automated_landscape/`):**\n",
    "- `loss_landscapes_df.pkl` - Structured DataFrame with landscapes and metadata (~variable size)\n",
    "- `raw_loss_landscape_array.npy` - Raw 3D numpy array (samples × grid_x × grid_y) (~variable size)\n",
    "- `config.yml` - Copy of the landscape generation configuration\n",
    "\n",
    "## **Scripts We'll Use**\n",
    "\n",
    "1. **`generate_hessian_eigenvector.py`** - Computes Hessian eigenvectors from config\n",
    "2. **`generate_loss_landscapes.py`** - Generates 2D loss landscapes from config  \n",
    "\n",
    "## **Quick Overview**\n",
    "\n",
    "The automated workflow consists of just two main commands:\n",
    "```bash\n",
    "# Step 1: Compute Hessian eigenvectors\n",
    "python generate_hessian_eigenvector.py hessian_config.yml\n",
    "\n",
    "# Step 2: Generate loss landscapes  \n",
    "python generate_loss_landscapes.py landscape_config.yml\n",
    "```\n",
    "\n",
    "Each script uses YAML configuration files to specify all parameters, making the process **reproducible, configurable, and suitable for batch processing**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1b102",
   "metadata": {},
   "source": [
    "## 1. Setup and Verify Demo Files\n",
    "\n",
    "First, let's import the necessary libraries and verify that our demo files are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dced83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "# Check if we're in the demo directory or need to navigate\n",
    "if os.path.basename(os.getcwd()) == 'demo':\n",
    "    os.chdir('..')\n",
    "    base_path = '.'\n",
    "    demo_path = 'demo'\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Base path: {base_path}\")\n",
    "print(f\"Demo path: {demo_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fffb8c",
   "metadata": {},
   "source": [
    "We will use the previously selected lowest error samples for Hessian eigenvector computation and the full dataset for loss landscape generation, just like how we did it in demo 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify demo files exist\n",
    "demo_files = {\n",
    "    'model': os.path.join('demo', 'demo_JVDFT_dHf_model.pt'),\n",
    "    'dataset': os.path.join('demo', 'demo_JVDFT_dHf_dataset_50.pkl'),\n",
    "    'low_error_dataset': os.path.join('demo', 'demo_JVDFT_dHf_dataset_lowest_20_error_samples_from_50.pkl')\n",
    "}\n",
    "\n",
    "print(\"Checking demo files:\")\n",
    "all_files_exist = True\n",
    "for name, path in demo_files.items():\n",
    "    if os.path.exists(path):\n",
    "        size = os.path.getsize(path)\n",
    "        print(f\"  {name}: {path} ({size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"  {name}: {path} - NOT FOUND\")\n",
    "        all_files_exist = False\n",
    "\n",
    "if all_files_exist:\n",
    "    print(\"\\nAll demo files are available!\")\n",
    "else:\n",
    "    print(\"\\nSome demo files are missing. Please ensure you have the demo files in the demo/ directory.\")\n",
    "\n",
    "# Quick peek at the dataset\n",
    "if os.path.exists(demo_files['dataset']):\n",
    "    df = pd.read_pickle(demo_files['dataset'])\n",
    "    print(f\"\\nDataset info:\")\n",
    "    print(f\"  Samples: {len(df)}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    print(f\"  Target (formation energy) range: {df['formation_energy_peratom'].min():.3f} to {df['formation_energy_peratom'].max():.3f}\")\n",
    "else:\n",
    "    print(\"\\nCannot load dataset for inspection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9888daa",
   "metadata": {},
   "source": [
    "## 2. Create Configuration for Hessian Eigenvector Computation\n",
    "\n",
    "Now we'll create a YAML configuration file for the first step: computing Hessian eigenvectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b6088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration for Hessian eigenvector computation\n",
    "hessian_config = {\n",
    "    'model_path': demo_files['model'],\n",
    "    'data_path': demo_files['low_error_dataset'], \n",
    "    'run_id': 'demo2_automated_hessian',\n",
    "    'target': 'formation_energy_peratom',\n",
    "    'device': 'cuda'  # Change to 'cpu' if no GPU available\n",
    "}\n",
    "\n",
    "# Save configuration to YAML file\n",
    "hessian_config_path = (os.path.join('demo', 'demo2_hessian_config.yml'))\n",
    "\n",
    "with open(hessian_config_path, 'w') as f:\n",
    "    yaml.dump(hessian_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"\\nConfiguration saved to: {hessian_config_path}\")\n",
    "\n",
    "# Display the generated YAML file\n",
    "print(f\"\\nContents of {hessian_config_path}:\")\n",
    "with open(hessian_config_path, 'r') as f:\n",
    "    hessian_config_dict = yaml.safe_load(f)\n",
    "\n",
    "display(hessian_config_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fed1a",
   "metadata": {},
   "source": [
    "### Configuration Explanation\n",
    "\n",
    "**Key Parameters for Hessian Computation:**\n",
    "\n",
    "- **`model_path`**: Path to the trained ALIGNN model checkpoint (.pt file)\n",
    "- **`data_path`**: Path to the dataset pickle file (.pkl) - script will use ALL samples in this file\n",
    "- **`run_id`**: Unique identifier that creates output folder `eigenvectors/{run_id}/`\n",
    "- **`target`**: Target property name in the dataset (column name)\n",
    "- **`device`**: Computation device ('cuda' for GPU, 'cpu' for CPU)\n",
    "\n",
    "**Important**: The script will use the **entire dataset** specified in `data_path`. For large datasets, this can be memory-intensive. Consider creating a subset if needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8238d",
   "metadata": {},
   "source": [
    "## 3. Execute Hessian Eigenvector Computation\n",
    "\n",
    "Now we'll run the automated script to compute the Hessian eigenvectors. This may take several minutes depending on your hardware and dataset size.\n",
    "\n",
    "```bash\n",
    "python generate_hessian_eigenvector.py hessian_config.yml\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e872084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"Starting Hessian eigenvector computation...\")\n",
    "print(\"This may take 2-3 minutes depending on your hardware and dataset size.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Run the hessian eigenvector script\n",
    "    cmd = ['python', 'generate_hessian_eigenvector.py', hessian_config_path]\n",
    "    print(f\"\\nExecuting: {' '.join(cmd)}\")\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)  # 30 min timeout\n",
    "    \n",
    "    end_time = time.time()\n",
    "    computation_time = end_time - start_time\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"\\nHessian computation completed successfully!\")\n",
    "        print(f\"Total time: {computation_time:.2f} seconds ({computation_time/60:.2f} minutes)\")\n",
    "        print(f\"\\nScript output:\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(f\"\\nError occurred during computation:\")\n",
    "        print(f\"Return code: {result.returncode}\")\n",
    "        print(f\"Error output: {result.stderr}\")\n",
    "        print(f\"Standard output: {result.stdout}\")\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(f\"\\nScript timed out after 30 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nUnexpected error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6e0244",
   "metadata": {},
   "source": [
    "## 4. Verify Hessian Results\n",
    "\n",
    "Let's check what files were created by the Hessian eigenvector computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a02c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the eigenvector output directory\n",
    "eigenvector_dir = os.path.join(base_path, 'eigenvectors', hessian_config['run_id'])\n",
    "\n",
    "print(f\"Checking eigenvector output directory: {eigenvector_dir}\")\n",
    "\n",
    "if os.path.exists(eigenvector_dir):\n",
    "    print(f\"Output directory exists!\")\n",
    "    \n",
    "    # List all files in the directory\n",
    "    files = os.listdir(eigenvector_dir)\n",
    "    print(f\"\\nFiles created:\")\n",
    "    for file in files:\n",
    "        file_path = os.path.join(eigenvector_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size = os.path.getsize(file_path)\n",
    "            print(f\"  {file} ({size:,} bytes)\")\n",
    "    \n",
    "    # Load and display eigenvalue information if available\n",
    "    eigenvalue_file = os.path.join(eigenvector_dir, 'eigenvalues.txt')\n",
    "    if os.path.exists(eigenvalue_file):\n",
    "        print(f\"\\nEigenvalue Information:\")\n",
    "        print(\"-\" * 30)\n",
    "        with open(eigenvalue_file, 'r') as f:\n",
    "            print(f.read())\n",
    "    \n",
    "    # Load and display config that was saved\n",
    "    config_file = os.path.join(eigenvector_dir, 'config.yml')\n",
    "    if os.path.exists(config_file):\n",
    "        print(f\"\\nSaved Configuration:\")\n",
    "        print(\"-\" * 25)\n",
    "        with open(config_file, 'r') as f:\n",
    "            saved_config = yaml.safe_load(f)\n",
    "            for key, value in saved_config.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(f\"\\nHessian eigenvector computation completed successfully!\")\n",
    "    print(f\"Results saved in: {eigenvector_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Output directory not found: {eigenvector_dir}\")\n",
    "    print(\"The Hessian computation may have failed or not completed yet.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029b2498",
   "metadata": {},
   "source": [
    "## 5. Create Configuration for Loss Landscape Generation\n",
    "\n",
    "Now that we have the Hessian eigenvectors, we can create the configuration for generating loss landscapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59fa468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration for loss landscape generation\n",
    "landscape_config = {\n",
    "    'model_path': demo_files['model'],\n",
    "    'data_path': demo_files['dataset'],\n",
    "    'target': 'formation_energy_peratom',\n",
    "    'eigenvector_folder_path': eigenvector_dir,  # Points to the results from step 1\n",
    "    'run_id': 'demo2_automated_landscape',\n",
    "    'steps': 20,  # Creates a 21x21 grid\n",
    "    'device': 'cuda',  # Change to 'cpu' if no GPU available\n",
    "    'scale_factor': 1.0,  # Scaling for eigenvector perturbations\n",
    "    'half': False  # Set to True to skip every other computation for speed\n",
    "}\n",
    "\n",
    "# Save configuration to YAML file\n",
    "landscape_config_path = os.path.join(demo_path, 'demo2_landscape_config.yml')\n",
    "\n",
    "print(\"Creating Loss Landscape configuration:\")\n",
    "\n",
    "\n",
    "with open(landscape_config_path, 'w') as f:\n",
    "    yaml.dump(landscape_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"\\nConfiguration saved to: {landscape_config_path}\")\n",
    "\n",
    "# Display the generated YAML file\n",
    "print(f\"\\nContents of {landscape_config_path}:\")\n",
    "print(\"-\" * 40)\n",
    "with open(landscape_config_path, 'r') as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f35d0",
   "metadata": {},
   "source": [
    "### Configuration Explanation\n",
    "\n",
    "**Key Parameters for Loss Landscape Generation:**\n",
    "\n",
    "- **`model_path`**: Same model as before\n",
    "- **`data_path`**: The full dataset you wish to compute loss landscape on\n",
    "- **`target`**: Same target property\n",
    "- **`eigenvector_folder_path`**: Path to the eigenvector results from Step 1\n",
    "- **`run_id`**: Creates output folder `computed_loss_landscapes/{run_id}/`\n",
    "- **`steps`**: Grid resolution\n",
    "- **`device`**: Computation device\n",
    "- **`scale_factor`**: Multiplier for eigenvector perturbation magnitude\n",
    "- **`half`**: Boolean to skip every other grid point (speeds up computation by ~2x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc10877",
   "metadata": {},
   "source": [
    "## 6. Execute Loss Landscape Generation\n",
    "\n",
    "Now we'll run the second script to generate the 2D loss landscapes. This step typically takes longer than the Hessian computation.\n",
    "\n",
    "```bash \n",
    "python generate_loss_landscapes.py landscape_config.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfbb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Loss Landscape generation...\")\n",
    "print(f\"Processing {len(df)} samples with {landscape_config['steps']}×{landscape_config['steps']} grids\")\n",
    "print(f\"Total model evaluations: ~{len(df) * landscape_config['steps']**2:,}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Run the loss landscape generation script\n",
    "    cmd = ['python', 'generate_loss_landscapes.py', landscape_config_path]\n",
    "    print(f\"\\nExecuting: {' '.join(cmd)}\")\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=3600)  # 60 min timeout\n",
    "    \n",
    "    end_time = time.time()\n",
    "    computation_time = end_time - start_time\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"\\nLoss landscape generation completed successfully!\")\n",
    "        print(f\"Total time: {computation_time:.2f} seconds ({computation_time/60:.2f} minutes)\")\n",
    "        print(f\"\\nScript output:\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(f\"\\nError occurred during generation:\")\n",
    "        print(f\"Return code: {result.returncode}\")\n",
    "        print(f\"Error output: {result.stderr}\")\n",
    "        print(f\"Standard output: {result.stdout}\")\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(f\"\\nScript timed out after 60 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nUnexpected error: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988c0dc",
   "metadata": {},
   "source": [
    "## 7. Verify Loss Landscape Results\n",
    "\n",
    "Let's examine the output files from the loss landscape generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95aea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the loss landscape output directory\n",
    "landscape_dir = os.path.join(base_path, 'computed_loss_landscapes', landscape_config['run_id'])\n",
    "\n",
    "print(f\"Checking loss landscape output directory: {landscape_dir}\")\n",
    "\n",
    "if os.path.exists(landscape_dir):\n",
    "    print(f\"Output directory exists!\")\n",
    "    \n",
    "    # List all files in the directory\n",
    "    files = os.listdir(landscape_dir)\n",
    "    print(f\"\\nFiles created:\")\n",
    "    total_size = 0\n",
    "    for file in files:\n",
    "        file_path = os.path.join(landscape_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            size = os.path.getsize(file_path)\n",
    "            total_size += size\n",
    "            print(f\"  {file} ({size:,} bytes)\")\n",
    "    \n",
    "    print(f\"\\nTotal output size: {total_size:,} bytes ({total_size/1024/1024:.2f} MB)\")\n",
    "    \n",
    "    # Load and examine the loss landscapes DataFrame if available\n",
    "    landscape_pkl = os.path.join(landscape_dir, 'loss_landscapes_df.pkl')\n",
    "    if os.path.exists(landscape_pkl):\n",
    "        print(f\"\\nLoading loss landscapes DataFrame...\")\n",
    "        try:\n",
    "            landscapes_df = pd.read_pickle(landscape_pkl)\n",
    "            print(f\"  Shape: {landscapes_df.shape}\")\n",
    "            print(f\"  Columns: {list(landscapes_df.columns)}\")\n",
    "            print(f\"  Sample JIDs: {landscapes_df['jid'].head().tolist()}\")\n",
    "            \n",
    "            # Check the landscape array shape\n",
    "            first_landscape = landscapes_df['raw_loss_landscapes'].iloc[0]\n",
    "            print(f\"  Individual landscape shape: {first_landscape.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading DataFrame: {str(e)}\")\n",
    "    \n",
    "    # Load and display the saved config\n",
    "    config_file = os.path.join(landscape_dir, 'config.yml')\n",
    "    if os.path.exists(config_file):\n",
    "        print(f\"\\nSaved Configuration:\")\n",
    "        print(\"-\" * 25)\n",
    "        with open(config_file, 'r') as f:\n",
    "            saved_config = yaml.safe_load(f)\n",
    "            for key, value in saved_config.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "    \n",
    "    print(f\"\\nLoss landscape generation completed successfully!\")\n",
    "    print(f\"Results saved in: {landscape_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Output directory not found: {landscape_dir}\")\n",
    "    print(\"The loss landscape generation may have failed or not completed yet.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "losslandscapefeb8gpu4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
