{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 4: Machine Learning Analysis of Loss Landscapes\n",
    "\n",
    "This notebook demonstrates how to apply **unsupervised machine learning techniques** to analyze loss landscape data and extract meaningful patterns. We'll explore the data structure, perform clustering, and quantify relationships between material properties and loss landscape characteristics.\n",
    "\n",
    "## **What This Demo Covers**\n",
    "\n",
    "This notebook teaches you how to:\n",
    "1. **Load and prepare processed data** from Demo 3\n",
    "2. **Explore data with interactive selectors** to choose properties and landscapes  \n",
    "3. **Apply dimensionality reduction** using UMAP and PCA\n",
    "4. **Perform clustering analysis** with K-Means and Spectral Clustering\n",
    "5. **Visualize relationships** between material properties and clusters\n",
    "6. **Quantify associations** using mutual information analysis\n",
    "\n",
    "## **Expected Input Data**\n",
    "\n",
    "This demo requires processed data from **Demo 3**:\n",
    "\n",
    "### **Required Input Files:**\n",
    "- `computed_loss_landscapes/demo2_automated_landscape/processed_loss_function_dict.pkl` - Processed loss landscape metrics\n",
    "- `computed_loss_landscapes/demo2_automated_landscape/feat_sample_df.pkl` - Enhanced sample features\n",
    "- `computed_loss_landscapes/demo2_automated_landscape/feat_sample_composition_df.pkl` - Chemical composition features\n",
    "- `computed_loss_landscapes/demo2_automated_landscape/feat_sample_structure_df.pkl` - Crystal structure features\n",
    "\n",
    "## **Key Analysis Methods**\n",
    "\n",
    "### **1. Dimensionality Reduction**\n",
    "- **UMAP (Uniform Manifold Approximation and Projection)**: Preserves local and global structure\n",
    "- **PCA (Principal Component Analysis)**: Linear dimensionality reduction with interpretable components\n",
    "\n",
    "### **2. Clustering Algorithms**\n",
    "- **K-Means Clustering**: Partitions data into k clusters based on feature similarity\n",
    "- **Spectral Clustering**: Uses eigenvalues of similarity matrix for non-linear cluster identification\n",
    "\n",
    "### **3. Property Analysis**\n",
    "- **Interactive visualization**: Explore relationships between material properties and loss landscapes\n",
    "- **Mutual information**: Quantify statistical dependencies between variables\n",
    "\n",
    "## **No Files Generated**\n",
    "\n",
    "Unlike previous demos, this notebook focuses on **interactive analysis and visualization**. All results are displayed within the notebook and no output files are created. This makes it perfect for **exploratory data analysis** and **parameter experimentation**.\n",
    "\n",
    "---\n",
    "\n",
    "**Let's explore the hidden patterns in our loss landscape data!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "### 1.1 Import Required Libraries\n",
    "\n",
    "We'll import all the necessary libraries for machine learning analysis, visualization, and data processing. This includes:\n",
    "\n",
    "- **Machine Learning**: scikit-learn for clustering, dimensionality reduction, and metrics\n",
    "- **Visualization**: matplotlib, seaborn for plotting \n",
    "- **Data Processing**: pandas, numpy for data manipulation\n",
    "- **Dimensionality Reduction**: UMAP, PCA for data visualization\n",
    "- **Interactive Widgets**: ipywidgets for parameter exploration\n",
    "- **Custom Utilities**: Our local modules for specialized functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, Checkbox, Dropdown, FloatSlider, fixed\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_kernels\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.linalg import eigh\n",
    "import umap\n",
    "from util.general import flatten_and_vstack, create_selectors\n",
    "from util.landscape_processing import restore_to_square_shape\n",
    "from util.plot import plot_loss_landscape, visualize_image_clusters, plot_categorical_data, plot_numerical_data, plot_umap_parameter_grid, plot_umap_scatter, plot_twin_umap_scatter\n",
    "from src.pca_analysis import visualize_top_pcs, plot_pairwise_pc, plot_explained_variance\n",
    "from src.spectral_clustering import manual_spectral_clustering\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from src.tilt_angle import compute_best_tilt\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"'force_all_finite' was renamed to 'ensure_all_finite'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configure Data Source\n",
    "\n",
    "Here we specify which folder contains our processed data from Demo 3. \n",
    "\n",
    "**You can modify this section to:**\n",
    "- Change the folder path to analyze different datasets\n",
    "- Add multiple folders to combine results from different experiments\n",
    "- Switch between different loss landscape analysis results\n",
    "\n",
    "**Current Configuration:**\n",
    "- Using results from `demo2_automated_landscape` (from Demo 2 + Demo 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [os.path.join('computed_loss_landscapes', 'demo2_automated_landscape')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Load Processed Data\n",
    "\n",
    "This section loads all the processed data files from Demo 3's post-processing step. We load:\n",
    "\n",
    "1. **Loss Function Metrics** (`processed_loss_function_dict.pkl`): Contains various loss landscape metrics like:\n",
    "   - `loss_at_origin`: Loss value at the original model position\n",
    "   - `average_loss`: Mean loss across the landscape\n",
    "   - `standard_deviation_of_loss`: Loss variability measure\n",
    "   - `euclidean_distance_best_to_original`: Distance to optimal point\n",
    "   - Transformed versions (log, z-score, min-max normalized)\n",
    "\n",
    "2. **Enhanced Sample Features** (`feat_sample_df.pkl`): Original sample data with additional computed features\n",
    "\n",
    "3. **Composition Features** (`feat_sample_composition_df.pkl`): Chemical composition descriptors from matminer\n",
    "\n",
    "4. **Structure Features** (`feat_sample_structure_df.pkl`): Crystal structure descriptors from matminer\n",
    "\n",
    "**Note:** If you have multiple experiment folders, this code will automatically merge all dictionaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function_dicts = []\n",
    "for folder in folders:\n",
    "    with open(os.path.join(folder,'processed_loss_function_dict.pkl'), 'rb') as file:\n",
    "        loss_function_dicts.append(pickle.load(file))\n",
    "\n",
    "\n",
    "# Merge all dictionaries from loss_function_dicts into a single dictionary\n",
    "merged_loss_function_dict = {}\n",
    "for d in loss_function_dicts:\n",
    "    for key, value in d.items():\n",
    "        if key not in merged_loss_function_dict:\n",
    "            merged_loss_function_dict[key] = value\n",
    "        else:\n",
    "            # If key exists, update/append values\n",
    "            merged_loss_function_dict[key].update(value)\n",
    "\n",
    "# Update the loss_function_dict to use merged version\n",
    "loss_function_dict = merged_loss_function_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(folders[0],'feat_sample_df.pkl'), 'rb') as file:\n",
    "    feat_sample_df = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(folders[0],'feat_sample_composition_df.pkl'), 'rb') as file:\n",
    "    feat_sample_composition_df = pickle.load(file)\n",
    "\n",
    "with open(os.path.join(folders[0],'feat_sample_structure_df.pkl'), 'rb') as file:\n",
    "    feat_sample_structure_df = pickle.load(file)\n",
    "\n",
    "sample_dict = {\n",
    "    'feat_sample_df': feat_sample_df,\n",
    "    'feat_sample_composition_df': feat_sample_composition_df,\n",
    "    'feat_sample_structure_df': feat_sample_structure_df}\n",
    "\n",
    "combined_dict = {**sample_dict, **loss_function_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interactive Data Selection\n",
    "\n",
    "### 2.1 Create Interactive Selectors\n",
    "\n",
    "This section creates interactive widgets that allow you to explore different combinations of:\n",
    "- **Material properties** (composition, structure, formation energy)\n",
    "- **Loss landscape metrics** (various processed metrics from Demo 3)\n",
    "- **Transformed loss landscapes**\n",
    "\n",
    "**How to use the selectors:**\n",
    "1. **Property Dict Selector**: Choose which data type (sample features, composition, structure)\n",
    "2. **Property Column Selector**: Pick specific properties within that data type  \n",
    "3. **Loss Function Selector**: Choose which loss landscape analysis results\n",
    "4. **Loss Function Column Selector**: Pick specific loss metrics\n",
    "\n",
    "**Available property types:**\n",
    "- `feat_sample_df`: Original sample properties (formation energy, bandgap, etc.)\n",
    "- `feat_sample_composition_df`: Chemical composition features (elemental fractions, compound descriptors)\n",
    "- `feat_sample_structure_df`: Crystal structure features (density, volume, symmetry)\n",
    "\n",
    "**Available loss metrics:**\n",
    "- Raw metrics: `loss_at_origin`, `average_loss`, `standard_deviation_of_loss`\n",
    "- Derived metrics: `is_original_loss_the_lowest`, `euclidean_distance_best_to_original`\n",
    "- Transformed versions: `log_*`, `z_*`, `minmax_*` variants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectors = create_selectors(sample_dict, loss_function_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended Demo Selections\n",
    "\n",
    "For this demonstration, we recommend using the following interactive widget selections to explore meaningful relationships between material properties and loss landscapes:\n",
    "\n",
    "#### **Material Properties**\n",
    "| Selection | Dataset | Property | Description |\n",
    "|-----------|---------|----------|-------------|\n",
    "| **Property 1** | `feat_sample_df` | `formation_energy_peratom` | Formation energy per atom (fundamental thermodynamic property) |\n",
    "| **Property 2** | `feat_sample_structure_df` | `density` | Material density (structural characteristic) |\n",
    "\n",
    "#### **Loss Landscape Data**\n",
    "| Selection | Dataset | Landscape Type | Description |\n",
    "|-----------|---------|----------------|-------------|\n",
    "| **Landscape 1** | `demo2_automated_landscape_mse` | `log_loss_landscape_array` | Log-transformed loss landscapes |\n",
    "| **Landscape 2** | `demo2_automated_landscape_mse` | `loss_landscape_array` | Raw loss landscape values |\n",
    "\n",
    "#### **Why These Selections?**\n",
    "- **Formation energy**: Directly related to material stability and synthesizability\n",
    "- **Density**: Captures structural compactness and packing efficiency  \n",
    "- **Raw vs Log landscapes**: Compare original vs transformed loss surface topology\n",
    "\n",
    "**Feel free to experiment with different combinations after running through this demo!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Extract Selected Data\n",
    "\n",
    "This cell extracts the specific properties and loss landscapes based on your widget selections above. \n",
    "\n",
    "**What gets extracted:**\n",
    "- `property_1` & `property_2`: Material properties for analysis and visualization\n",
    "- `landscape_array_1` & `landscape_array_2`: Loss landscape data arrays for dimensionality reduction\n",
    "\n",
    "**Note:** You can modify the widget selections above and re-run this cell to analyze different property-landscape combinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_1 = combined_dict[selectors['property_dict_selector_1'].value][selectors['property_column_selector_1'].value].copy()\n",
    "property_2 = combined_dict[selectors['property_dict_selector_2'].value][selectors['property_column_selector_2'].value].copy()\n",
    "landscape_array_1 = loss_function_dict[selectors['loss_function_selector_1'].value][selectors['loss_function_column_selector_1'].value].copy()\n",
    "landscape_array_2 = loss_function_dict[selectors['loss_function_selector_2'].value][selectors['loss_function_column_selector_2'].value].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dimensionality Reduction with UMAP\n",
    "\n",
    "### 3.1 UMAP Parameter Grid Search\n",
    "\n",
    "**UMAP (Uniform Manifold Approximation and Projection)** is a powerful dimensionality reduction technique that preserves both local and global data structure.\n",
    "\n",
    "**Key UMAP Parameters to explore:**\n",
    "\n",
    "1. **`n_neighbors` (2-50)**: \n",
    "   - **Low values (2-5)**: Focus on local structure, more fragmented clusters\n",
    "   - **High values (30-50)**: Emphasize global structure, smoother embeddings\n",
    "\n",
    "2. **`min_dist` (0.0-1.0)**:\n",
    "   - **Low values (0.0-0.1)**: Tighter clusters, points can be very close\n",
    "   - **High values (0.5-1.0)**: More spread out, prevents overlapping\n",
    "\n",
    "**What this visualization shows:**\n",
    "- Grid of UMAP embeddings with different parameter combinations\n",
    "- Helps you identify which parameters reveal the most interesting structure in your loss landscape data\n",
    "\n",
    "**How to interpret:**\n",
    "- Look for parameter combinations that show clear clustering patterns\n",
    "- Consider how the structure relates to your domain knowledge of the materials\n",
    "\n",
    "**Parameter lists you can modify:**\n",
    "```python\n",
    "n_neighbors_list = [2, 5, 15, 20, 30, 50]      # Try different neighbor counts\n",
    "min_dist_list = [0, 0.01, 0.05, 0.1, 0.5, 1.0] # Try different minimum distances\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the selected loss landscape array from the dictionary using the chosen selectors\n",
    "landscape_array_1 = loss_function_dict[selectors['loss_function_selector_1'].value][selectors['loss_function_column_selector_1'].value].copy()\n",
    "\n",
    "# Define a list of possible values for the number of neighbors parameter in UMAP\n",
    "n_neighbors_list = [2, 5, 15, 20, 30, 50]\n",
    "\n",
    "# Define a list of possible values for the minimum distance parameter in UMAP\n",
    "min_dist_list = [0, 0.01, 0.05, 0.1, 0.5, 1.0]\n",
    "\n",
    "# Plot the UMAP parameter grid using the defined hyperparameter lists\n",
    "plot_umap_parameter_grid(landscape_array_1, n_neighbors_list, min_dist_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Apply Optimal UMAP Parameters\n",
    "\n",
    "Based on the parameter grid above, we select optimal UMAP parameters and create the final embedding.\n",
    "\n",
    "**Current Parameters:**\n",
    "- `n_neighbors=15`: Balanced focus on local and global structure  \n",
    "- `min_dist=0.1`: Allows tight clusters while preventing excessive overlap\n",
    "\n",
    "**You can modify these parameters:**\n",
    "```python\n",
    "n_neighbors, min_dist = 15, 0.1  # Experiment with different values!\n",
    "```\n",
    "\n",
    "**Parameter recommendations:**\n",
    "- For **materials discovery**: Try `n_neighbors=30, min_dist=0.0` (emphasize global patterns)\n",
    "- For **anomaly detection**: Try `n_neighbors=5, min_dist=0.5` (highlight outliers)\n",
    "- For **cluster analysis**: Try `n_neighbors=15, min_dist=0.1` (balanced view)\n",
    "\n",
    "**Output:**\n",
    "- 2D UMAP embedding saved as `umap_transformed_data`\n",
    "- Scatter plot showing the embedding structure\n",
    "- Each point represents one material sample's loss landscape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set UMAP hyperparameters for dimensionality reduction\n",
    "n_neighbors, min_dist = 15, 0.1\n",
    "\n",
    "# Initialize UMAP with the specified hyperparameters and a fixed random state for reproducibility\n",
    "umap_reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=2, random_state=42)\n",
    "\n",
    "# Apply UMAP to fit and transform the flattened landscape array data\n",
    "umap_transformed_data = umap_reducer.fit_transform(flatten_and_vstack(landscape_array_1))\n",
    "\n",
    "# Visualize the UMAP-transformed data using a scatter plot\n",
    "plot_umap_scatter(umap_transformed_data, n_neighbors=n_neighbors, min_dist=min_dist, landscape_array=landscape_array_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Loss Landscape Tilt Analysis\n",
    "\n",
    "### 4.1 Compute Tilt Angles\n",
    "\n",
    "As you have seen at the end of demo 1, most loss landscapes show up as straight lines with different slopes.\n",
    "\n",
    "This section analyzes the **directionality** in loss landscapes by computing the tilt angle of the loss ridge.\n",
    "\n",
    "**What this analysis reveals:**\n",
    "- **Tilt angle**: Direction of steepest descent in the loss landscape\n",
    "- **Relationship to material properties**: How loss landscape orientation correlates with formation energy\n",
    "\n",
    "**Key function: `compute_best_tilt()`**\n",
    "- Fits lines to loss minima in both row and column directions\n",
    "- Selects the fit with higher R² value\n",
    "- Returns the tilt angle in the specified convention\n",
    "\n",
    "**Parameters you can modify:**\n",
    "- `degrees=True`: Return angle in degrees (vs radians)\n",
    "- `angle_mode='unsigned180'`: Angle range (0°-180°) vs `'signed90'` (-90°-90°)\n",
    "\n",
    "**Interpretation:**\n",
    "- **0° or 180°**: Vertical loss ridge\n",
    "- **90°**: Horizontal loss ridge  \n",
    "- **45°**: Diagonal loss ridge\n",
    "\n",
    "The histogram and scatter plot help identify if certain materials have preferred loss landscape orientations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = []\n",
    "for i in range(len(landscape_array_1.to_list())):\n",
    "    angle, _ = compute_best_tilt(landscape_array_1.to_list()[i], degrees=True,angle_mode='unsigned180')\n",
    "    angles.append(angle)\n",
    "\n",
    "#plot histogram of angles\n",
    "plt.hist(angles, bins=30, alpha=0.5, color='blue')\n",
    "plt.title('Histogram of Tilt Angles')\n",
    "plt.xlabel('Tilt Angle (degrees)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Plot predicted values as a function of tilt angle\n",
    "true_vals = combined_dict['feat_sample_df']['formation_energy_peratom']\n",
    "\n",
    "# Add a vertical line at x=0 and a horizontal line at y=-1 to the previous plot\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.scatter(angles, true_vals, alpha=0.5, color='royalblue', edgecolor='k')\n",
    "plt.xlabel('Tilt Angle (degrees)')\n",
    "plt.ylabel('Formation Energy per Atom (eV/atom)')\n",
    "plt.title('Formation Energy per Atom vs. Tilt Angle')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Principal Component Analysis (PCA)\n",
    "\n",
    "### 5.1 Linear Dimensionality Reduction\n",
    "\n",
    "**PCA** provides a linear approach to dimensionality reduction that's complementary to UMAP's non-linear approach.\n",
    "\n",
    "**What PCA reveals:**\n",
    "- **Principal components**: Linear combinations of loss landscape features that capture maximum variance\n",
    "- **Explained variance**: How much information each component retains\n",
    "- **Component interpretation**: Which aspects of loss landscapes drive the main variations\n",
    "\n",
    "**Key parameters to explore:**\n",
    "\n",
    "1. **`n_components`**: \n",
    "   - `None` (current): Retain all components for full analysis\n",
    "   - Integer: Specify exact number of components to keep\n",
    "   - Float (0.0-1.0): Retain components explaining this fraction of variance\n",
    "\n",
    "2. **Interactive sliders:**\n",
    "   - `n_pcs_to_visualize`: How many PC pairs to plot (1-10)\n",
    "   - `n_pcs_to_analyze`: How many top PCs to examine in detail (2-10)\n",
    "\n",
    "**Outputs:**\n",
    "- **Explained variance plot**: Shows information content of each PC\n",
    "- **Pairwise PC plots**: 2D scatter plots of different PC combinations  \n",
    "- **PC visualization**: Heatmaps showing what each PC represents\n",
    "\n",
    "**Comparison with UMAP:**\n",
    "- **PCA**: Reveals linear relationships, interpretable components\n",
    "- **UMAP**: Captures non-linear structure, better for clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and flatten the selected loss landscape array for PCA analysis\n",
    "flattened_landscape_array_1 = flatten_and_vstack(landscape_array_1)\n",
    "\n",
    "# Set the number of components for PCA to retain 98% of variance\n",
    "n_components = None\n",
    "pca = PCA(n_components=n_components)\n",
    "# Transform the data using PCA\n",
    "pca_transformed_data = pca.fit_transform(flattened_landscape_array_1)\n",
    "\n",
    "# Plot the explained variance to understand the contribution of each principal component\n",
    "plot_explained_variance(pca)\n",
    "\n",
    "# Define an interactive function for PCA analysis and visualization\n",
    "def interactive_pca_analysis(n_pcs_to_visualize, n_pcs_to_analyze):\n",
    "    # Plot pairwise principal components for visualization\n",
    "    plot_pairwise_pc(pca_transformed_data, n_pcs_to_visualize)\n",
    "    # Visualize the top principal components\n",
    "    visualize_top_pcs(pca, n_pcs_to_analyze)\n",
    "\n",
    "# Create interactive sliders for selecting the number of principal components to visualize and analyze\n",
    "interact(interactive_pca_analysis, n_pcs_to_visualize=IntSlider(min=1, max=10, step=1, value=3), n_pcs_to_analyze=IntSlider(min=2, max=10, step=1, value=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. K-Means Clustering Analysis\n",
    "\n",
    "### 6.1 Determine Optimal Number of Clusters\n",
    "\n",
    "**K-Means clustering** partitions data into k clusters by minimizing within-cluster variance.\n",
    "\n",
    "**The Elbow Method:**\n",
    "- **Inertia**: Sum of squared distances from points to their cluster centers\n",
    "- **Elbow point**: Where adding more clusters provides diminishing returns\n",
    "- **Optimal k**: Usually where the curve \"bends\" most sharply\n",
    "\n",
    "**Parameters you can modify:**\n",
    "```python\n",
    "k_values = range(2, 11)  # Try different ranges like range(2, 20)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and copy the selected loss landscape array for K-means clustering\n",
    "landscape_array_1 = loss_function_dict[selectors['loss_function_selector_1'].value][selectors['loss_function_column_selector_1'].value].copy()\n",
    "\n",
    "# Initialize a list to store inertia values for different numbers of clusters\n",
    "inertias = []\n",
    "# Define the range of k values (number of clusters) to evaluate\n",
    "k_values = range(2, 11)\n",
    "\n",
    "# Iterate over each k value to perform K-means clustering\n",
    "for k in k_values:\n",
    "    # Initialize K-means with the current number of clusters and a fixed random state for reproducibility\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    # Fit K-means to the flattened landscape array data\n",
    "    kmeans.fit(flatten_and_vstack(landscape_array_1))\n",
    "    # Append the inertia (sum of squared distances to the nearest cluster center) to the list\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve to visualize the inertia for each k value\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(k_values, inertias, 'bo-')  # Plot inertia values as a line with blue circle markers\n",
    "plt.xlabel('Number of Clusters (k)')  # Label the x-axis\n",
    "plt.ylabel('Inertia')  # Label the y-axis\n",
    "plt.title('Elbow Plot for K-means Clustering')  # Set the title of the plot\n",
    "plt.grid(True)  # Enable grid for better readability\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Interactive K-Means Visualization\n",
    "\n",
    "This interactive section lets you explore different numbers of clusters and see how they appear in both UMAP and PCA space.\n",
    "\n",
    "**Interactive slider: `n_k_means_clusters`**\n",
    "- **Range**: 2-20 clusters\n",
    "- **Default**: 3 clusters (good starting point)\n",
    "\n",
    "**Dual visualization:**\n",
    "1. **UMAP scatter plot**: Shows clusters in non-linear reduced space\n",
    "   - Colors represent different cluster assignments\n",
    "   - Points that are close in UMAP space tend to have similar loss landscapes\n",
    "\n",
    "2. **PCA pairwise plots**: Shows clusters in linear reduced space\n",
    "   - Multiple 2D projections of the first 4 principal components\n",
    "   - Reveals linear separability of clusters\n",
    "\n",
    "**How to use this interactively:**\n",
    "1. Start with k=3 and observe cluster patterns\n",
    "2. Increase k gradually and watch how clusters split\n",
    "3. Compare UMAP vs PCA representations\n",
    "4. Look for consistent cluster boundaries across both methods\n",
    "\n",
    "**Good clusters typically:**\n",
    "- Are well-separated in both UMAP and PCA space\n",
    "- Have roughly balanced sizes\n",
    "- Make physical/chemical sense for your materials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn.cluster._kmeans')\n",
    "\n",
    "def run_kmeans_and_plot(n_k_means_clusters):\n",
    "    # Initialize and fit K-means clustering with the specified number of clusters\n",
    "    kmeans = KMeans(n_clusters=n_k_means_clusters, random_state=42)\n",
    "    kmeans.fit(flatten_and_vstack(landscape_array_1))\n",
    "    \n",
    "    # Retrieve the cluster labels from the fitted K-means model\n",
    "    k_means_labels = kmeans.labels_\n",
    "    \n",
    "    # Plot the UMAP scatter plot with the K-means cluster labels\n",
    "    plot_umap_scatter(\n",
    "        umap_transformed_data, \n",
    "        labels=k_means_labels, \n",
    "        label_name='K-means Clusters', \n",
    "        label_type='categorical', \n",
    "        n_neighbors=n_neighbors, \n",
    "        min_dist=min_dist, \n",
    "        landscape_array=landscape_array_1\n",
    "    )\n",
    "    \n",
    "    # Plot pairwise principal components with the K-means cluster labels\n",
    "    plot_pairwise_pc(\n",
    "        pca_transformed_data, \n",
    "        4, \n",
    "        labels=k_means_labels, \n",
    "        label_name='K-means Clusters', \n",
    "        label_type='continuous'\n",
    "    )\n",
    "\n",
    "# Create an interactive slider to select the number of clusters for K-means\n",
    "interact(run_kmeans_and_plot, n_k_means_clusters=IntSlider(min=2, max=20, step=1, value=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Visualize Cluster Representatives\n",
    "\n",
    "This section provides a detailed look at the actual loss landscapes within each cluster.\n",
    "\n",
    "**Fixed clustering**: Uses k=2 for clear comparison between two main groups\n",
    "\n",
    "**What you'll see:**\n",
    "- **UMAP plot**: Shows the 2-cluster assignment in embedding space\n",
    "- **Loss landscape grid**: Shows up to 20 example loss landscapes from each cluster\n",
    "\n",
    "**Parameters you can modify:**\n",
    "```python\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)  # Try different k values\n",
    "max_arrays_per_cluster=20  # Show more/fewer examples per cluster\n",
    "```\n",
    "\n",
    "**How to interpret the landscape visualization:**\n",
    "- **Cluster consistency**: Do landscapes within a cluster look similar?\n",
    "- **Cluster differences**: How do the landscape patterns differ between clusters?\n",
    "- **Outliers**: Are there landscapes that don't fit their assigned cluster well?\n",
    "\n",
    "**This analysis helps validate that:**\n",
    "- Clusters correspond to meaningful differences in loss landscape structure\n",
    "- The clustering algorithm is capturing interpretable patterns\n",
    "- The number of clusters is appropriate for your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape_array_1 = loss_function_dict[selectors['loss_function_selector_1'].value][selectors['loss_function_column_selector_1'].value].copy()\n",
    "\n",
    "#save k_means_labels\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(flatten_and_vstack(landscape_array_1))\n",
    "k_means_labels = kmeans.labels_\n",
    "\n",
    "plot_umap_scatter(umap_transformed_data, labels=k_means_labels, label_name='k-MEANS Clusters', label_type='continuous', n_neighbors=n_neighbors, min_dist=min_dist, landscape_array=landscape_array_1)\n",
    "\n",
    "visualize_image_clusters(landscape_array_1, k_means_labels,max_arrays_per_cluster=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Spectral Clustering Analysis\n",
    "\n",
    "### 7.1 Interactive Spectral Clustering\n",
    "\n",
    "**Spectral clustering** uses eigenvalues of similarity matrices to identify clusters, making it effective for non-convex cluster shapes that K-means might miss.\n",
    "\n",
    "**Key parameters to explore:**\n",
    "\n",
    "1. **`affinity_type`**:\n",
    "   - **`'nearest_neighbors'`**: Uses k-nearest neighbor graph (good for local structure)\n",
    "   - **`'rbf'`**: Uses radial basis function (good for smooth density variations)\n",
    "\n",
    "2. **`affinity_param`**:\n",
    "   - For `'nearest_neighbors'`: Number of neighbors (5-50)\n",
    "   - For `'rbf'`: Gamma parameter (0.1-10, higher = more localized)\n",
    "\n",
    "3. **`n_clusters`**: Number of clusters to find (2-10)\n",
    "\n",
    "**Interactive options:**\n",
    "- **`visualize_affinity_scree`**: Shows the affinity matrix heatmap\n",
    "- **`visualize_in_2d`**: Displays clusters in UMAP and PCA space\n",
    "- **`visualize_image`**: Shows example loss landscapes per cluster\n",
    "\n",
    "**How to use this section:**\n",
    "1. Start with `affinity_type='nearest_neighbors'` and `affinity_param=13`\n",
    "2. Try different numbers of neighbors and observe cluster changes\n",
    "3. Compare with `affinity_type='rbf'` to see different cluster shapes\n",
    "4. Enable visualization options to understand cluster quality\n",
    "\n",
    "**Spectral vs K-means:**\n",
    "- **Spectral**: Can find non-spherical clusters, considers global structure\n",
    "- **K-means**: Assumes spherical clusters, faster computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualized_spectral_clustering(data, data_visualize, affinity_type, affinity_param, visualize_affinity_scree, n_clusters, visualize_in_2d, visualize_image):\n",
    "        # Perform spectral clustering on the data with specified parameters\n",
    "        spectral_clustering = SpectralClustering(n_clusters=n_clusters, gamma = affinity_param, affinity=affinity_type, n_neighbors=int(affinity_param))\n",
    "        label = spectral_clustering.fit_predict(data)\n",
    "\n",
    "        if visualize_affinity_scree:\n",
    "            # Plot the affinity matrix\n",
    "            plt.figure(figsize=(6,5))\n",
    "            heatmap = sns.heatmap(spectral_clustering.affinity_matrix_.toarray(), cmap='viridis')\n",
    "            plt.title('Affinity Matrix Heatmap')\n",
    "            plt.show()\n",
    "\n",
    "        # Extract the affinity matrix from the SpectralClustering object\n",
    "        # Check if 2D visualization is enabled\n",
    "        if visualize_in_2d:\n",
    "            # Plot UMAP scatter plot with spectral cluster labels\n",
    "            plot_umap_scatter(umap_transformed_data, labels=label, label_name='Spectral Clusters', label_type='continuous', n_neighbors=n_neighbors, min_dist=min_dist, landscape_array=landscape_array_1)\n",
    "            # Plot pairwise principal components with spectral cluster labels\n",
    "            plot_pairwise_pc(pca_transformed_data, 3, labels=label, label_name='Spectral Clusters', label_type='continuous')\n",
    "\n",
    "        # Check if image visualization is enabled\n",
    "        if visualize_image:\n",
    "            # Visualize image clusters based on spectral clustering labels\n",
    "            visualize_image_clusters(data_visualize, label,max_arrays_per_cluster=30)\n",
    "        else:\n",
    "            # Print message if visualization is disabled\n",
    "            print(\"Visualization is disabled. Enable visualization options to view results.\")\n",
    "\n",
    "# Copy the selected loss function arrays for further processing\n",
    "landscape_array_1 = loss_function_dict[selectors['loss_function_selector_1'].value][selectors['loss_function_column_selector_1'].value].copy()\n",
    "\n",
    "# Create an interactive widget for spectral clustering visualization\n",
    "interact(visualized_spectral_clustering,\n",
    "        data=fixed(flatten_and_vstack(landscape_array_1)),  # Flatten and stack the first landscape array\n",
    "        data_visualize=fixed(landscape_array_2),  # Use the second landscape array for visualization\n",
    "        affinity_type=Dropdown(options=['rbf', 'nearest_neighbors'], value='nearest_neighbors', description='Affinity Type'),  # Dropdown for selecting affinity type\n",
    "        affinity_param=FloatSlider(min=0.1, max=50, step=0.1, value=13, description='σ/Neighbors'),  # Slider for affinity parameter\n",
    "        visualize_affinity_scree=Checkbox(value=False, description='Affinity Plot'),  # Checkbox for scree plot visualization\n",
    "        n_clusters=IntSlider(min=2, max=10, step=1, value=3, description='Clusters'),  # Slider for number of clusters\n",
    "        visualize_in_2d=Checkbox(value=False, description='Visualize in 2D'),  # Checkbox for 2D visualization\n",
    "        visualize_image=Checkbox(value=False, description='Visualize Image'))  # Checkbox for image visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Save Spectral Clustering Results\n",
    "\n",
    "This cell creates a fixed spectral clustering result for comparison with K-means.\n",
    "\n",
    "**Fixed parameters:**\n",
    "- `n_clusters=3`: Three-cluster solution\n",
    "- `affinity='nearest_neighbors'`: k-NN based similarity\n",
    "- `n_neighbors=15`: Moderate neighborhood size\n",
    "\n",
    "**You can modify these parameters:**\n",
    "```python\n",
    "spectral_clustering = SpectralClustering(\n",
    "    n_clusters=2,           # Try 2-6 clusters\n",
    "    affinity='nearest_neighbors',  # Or 'rbf'\n",
    "    n_neighbors=int(15)     # Try 5-30 neighbors\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landscape_array_1 = loss_function_dict[selectors['loss_function_selector_1'].value][selectors['loss_function_column_selector_1'].value].copy()\n",
    "\n",
    "spectral_clustering = SpectralClustering(n_clusters=2, affinity='nearest_neighbors', n_neighbors=int(15))\n",
    "spectral_labels = spectral_clustering.fit_predict(flatten_and_vstack(landscape_array_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Compare K-means vs Spectral Clustering\n",
    "\n",
    "This visualization shows both clustering methods side-by-side to compare their results.\n",
    "\n",
    "**Twin UMAP plot shows:**\n",
    "- **Left panel**: K-means cluster assignments\n",
    "- **Right panel**: Spectral clustering assignments\n",
    "- **Same UMAP embedding**: Both use identical dimensional reduction\n",
    "\n",
    "**What to look for:**\n",
    "- **Agreement**: Do both methods identify similar cluster boundaries?\n",
    "- **Differences**: Where do they disagree and why?\n",
    "- **Cluster shapes**: Does spectral clustering find non-spherical patterns that K-means misses?\n",
    "\n",
    "**Parameters you can modify:**\n",
    "```python\n",
    "plot_twin_umap_scatter(\n",
    "    umap_data=umap_transformed_data, \n",
    "    n_neighbors=20,     # UMAP neighbors for display\n",
    "    min_dist=0.05,      # UMAP min_dist for display\n",
    "    labels1=k_means_labels, \n",
    "    labels2=spectral_labels,\n",
    "    # ... other parameters\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_twin_umap_scatter(umap_data=umap_transformed_data, n_neighbors=20, min_dist=0.05, labels1=k_means_labels, labels2=spectral_labels, label_name1='K-Means Clusters', label_name2='Spectral Clusters', label_type='continuous', landscape_array=landscape_array_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. DBSCAN Clustering (Optional)\n",
    "\n",
    "### 8.1 Density-Based Clustering Parameter Grid\n",
    "\n",
    "**DBSCAN (Density-Based Spatial Clustering)** identifies clusters based on point density, automatically determining the number of clusters and identifying outliers.\n",
    "\n",
    "**Key DBSCAN parameters:**\n",
    "\n",
    "1. **`eps`**: Maximum distance for points to be considered neighbors\n",
    "   - **Small values**: More clusters, tighter groups\n",
    "   - **Large values**: Fewer clusters, more points as noise\n",
    "\n",
    "2. **`min_samples`**: Minimum points needed to form a cluster\n",
    "   - **Small values**: More sensitive to local density variations\n",
    "   - **Large values**: Requires stronger evidence for cluster formation\n",
    "\n",
    "**Parameter grid exploration:**\n",
    "- **`eps_values`**: Logarithmic scale from ~6.3 to 31.6\n",
    "- **`min_samples_values`**: Linear scale from 1 to 7\n",
    "\n",
    "**How to interpret the grid:**\n",
    "- **Colors**: Different clusters (noise points usually in dark)\n",
    "- **Good parameters**: Clear cluster separation with minimal noise\n",
    "- **Too restrictive**: Most points labeled as noise (dark)\n",
    "- **Too permissive**: Everything in one large cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the selected loss function array for DBSCAN analysis\n",
    "landscape_array_1 = loss_function_dict[selectors['loss_function_selector_1'].value][selectors['loss_function_column_selector_1'].value].copy()\n",
    "\n",
    "# Define a range of eps values using a logarithmic scale\n",
    "eps_values = np.logspace(0.8, 1.5, num=8)  # Log scale from approximately 6.3 to 31.6\n",
    "\n",
    "# Define a range of min_samples values using a linear scale\n",
    "min_samples_values = np.arange(1, 8)  # Linear scale from 1 to 7\n",
    "\n",
    "# Create a grid of subplots with dimensions based on eps and min_samples values\n",
    "fig, axs = plt.subplots(len(eps_values), len(min_samples_values), figsize=(12, 12))\n",
    "fig.suptitle('DBSCAN on UMAP Reduced Data', fontsize=16)  # Set the main title for the figure\n",
    "\n",
    "# Iterate over each combination of eps and min_samples to perform DBSCAN\n",
    "for i, eps in enumerate(eps_values):\n",
    "    for j, min_samples in enumerate(min_samples_values):\n",
    "        # Initialize DBSCAN with the current eps and min_samples parameters\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        \n",
    "        # Fit DBSCAN and predict cluster labels on the UMAP reduced data\n",
    "        dbscan_labels = dbscan.fit_predict(flatten_and_vstack(landscape_array_1))\n",
    "        \n",
    "        # Plot the DBSCAN clustering result in the corresponding subplot\n",
    "        ax = axs[i, j]\n",
    "        scatter = ax.scatter(umap_transformed_data[:, 0], umap_transformed_data[:, 1], c=dbscan_labels, cmap='viridis', s=5)\n",
    "        ax.set_ylabel(f'eps={eps}', fontsize=8)  # Label the y-axis with the current eps value\n",
    "        ax.set_xlabel(f'min_samples={min_samples}', fontsize=8)  # Label the x-axis with the current min_samples value\n",
    "        ax.label_outer()  # Hide x and y labels for inner plots to reduce clutter\n",
    "\n",
    "# Add a legend to the figure to identify clusters\n",
    "fig.legend(*scatter.legend_elements(), title=\"Clusters\", loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "\n",
    "# Adjust the layout to ensure the main title and subplots are properly spaced\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()  # Display the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Property-Cluster Relationship Analysis\n",
    "\n",
    "### 9.1 Compare Material Properties with Clustering Results\n",
    "\n",
    "This final analysis explores whether the clustering patterns discovered in loss landscapes correlate with material properties.\n",
    "\n",
    "**Analysis setup:**\n",
    "- **`n_clusters=4`**: Use 4-cluster solutions for comparison\n",
    "- **`n_bins=4`**: Bin continuous properties into 4 categories (if needed)\n",
    "\n",
    "**What this section compares:**\n",
    "1. **K-means clustering**: Based purely on loss landscape similarity\n",
    "2. **Material properties**: Chemical/physical characteristics (formation energy, etc.)\n",
    "\n",
    "**Key visualization:**\n",
    "- **Twin UMAP plot**: Shows K-means clusters vs selected material property\n",
    "- **Left panel**: Clusters from unsupervised learning  \n",
    "- **Right panel**: Material property values (continuous coloring)\n",
    "\n",
    "**Mutual Information Score:**\n",
    "- **Range**: 0 (no relationship) to ~1 (strong relationship)\n",
    "- **Current result**: ~0.054 (weak relationship)\n",
    "- **Interpretation**: Loss landscape patterns show minimal correlation with the selected property\n",
    "\n",
    "**Parameters you can modify:**\n",
    "```python\n",
    "n_clusters, n_bins = 4, 4          # Try different numbers\n",
    "property_1 = combined_dict[...]     # Select different properties via selectors above\n",
    "```\n",
    "\n",
    "**What different MI scores mean:**\n",
    "- **0.0-0.1**: Very weak relationship\n",
    "- **0.1-0.3**: Weak relationship  \n",
    "- **0.3-0.7**: Moderate relationship\n",
    "- **0.7+**: Strong relationship\n",
    "\n",
    "This analysis helps determine if loss landscape clustering reveals chemically meaningful patterns or if it captures purely computational/numerical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters, n_bins = 4, 4\n",
    "\n",
    "property_1 = combined_dict[selectors['property_dict_selector_1'].value][selectors['property_column_selector_1'].value].copy()\n",
    "binned_labels = plot_numerical_data(property_1, bin_number=n_bins, display_stats=False)\n",
    "\n",
    "spectral_labels = manual_spectral_clustering(n_clusters=n_clusters, data=flatten_and_vstack(landscape_array_1),affinity_type='knn',affinity_param=13)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "kmeans.fit(flatten_and_vstack(landscape_array_1))\n",
    "k_means_labels = kmeans.labels_\n",
    "\n",
    "plot_twin_umap_scatter(\n",
    "    umap_data=umap_transformed_data,\n",
    "    n_neighbors=20,\n",
    "    min_dist=0.05,\n",
    "    labels1=k_means_labels,\n",
    "    label_name1='K-Means Clusters',\n",
    "    labels2=property_1,\n",
    "    label_name2=f'Binned {property_1.name}',\n",
    "    label_type='continuous',\n",
    "    landscape_array=landscape_array_1\n",
    ")\n",
    "\n",
    "mi = mutual_info_score(k_means_labels, binned_labels)\n",
    "print(f\"The mutual information score between the two labels is: {mi}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACSURP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
